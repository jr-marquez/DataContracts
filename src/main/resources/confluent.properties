# Required connection configs for Kafka producer, consumer, and admin
bootstrap.servers=<bootstrap server>
security.protocol=SASL_SSL
sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username='<apikey>' password='<apisecret>';
sasl.mechanism=PLAIN
# Required for correctness in Apache Kafka clients prior to 2.6
client.dns.lookup=use_all_dns_ips

# Best practice for higher availability in Apache Kafka clients prior to 3.0
session.timeout.ms=45000

# Best practice for Kafka producer to prevent data loss
acks=all

# Required connection configs for Confluent Cloud Schema Registry
schema.registry.url=<SR url>
basic.auth.credentials.source=USER_INFO
basic.auth.user.info=<srapikey>:<srapisecret>

# Best practice for Kafka producer to prevent data loss
key.serializer=org.apache.kafka.common.serialization.StringSerializer
value.serializer=io.confluent.kafka.serializers.KafkaAvroSerializer

#Data Contracts
#Validation
rule.executors=transformCustomerNull,maskPCI,checkAmount
rule.executors.checkAmount.class=io.confluent.kafka.schemaregistry.rules.cel.CelExecutor
rule.executors.transformCustomerNull.class=io.confluent.kafka.schemaregistry.rules.cel.CelFieldExecutor
rule.executors.maskPCI.class=io.confluent.kafka.schemaregistry.rules.cel.CelFieldExecutor

#Action
rule.actions=checkAmount
rule.actions.checkAmount.class=io.confluent.kafka.schemaregistry.rules.DlqAction
rule.actions.checkAmount.param.topic=transactions-alert
rule.actions.checkAmount.param.bootstrap.servers= <bootsrap>
rule.actions.checkAmount.param.security.protocol=SASL_SSL
rule.actions.checkAmount.param.sasl.mechanism=PLAIN
rule.actions.checkAmount.param.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username='<apikey>' password='<apisecret>';

#Required since we manually create schemas
use.latest.version=true
auto.register.schemas=false

#topicinfo
topic=transactions
max.in.flight.requests.per.connection=1
wrapped.key.serializer=org.apache.kafka.common.serialization.StringSerializer